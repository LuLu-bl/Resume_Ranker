{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Ck3adQSsX-z8","outputId":"a10c81b6-e46b-4a64-f312-fefd8d95f922"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: python-pdfbox in /usr/local/lib/python3.8/dist-packages (0.1.8.1)\n","Requirement already satisfied: jpype1 in /usr/local/lib/python3.8/dist-packages (from python-pdfbox) (1.4.1)\n","Requirement already satisfied: appdirs in /usr/local/lib/python3.8/dist-packages (from python-pdfbox) (1.4.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from python-pdfbox) (57.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from jpype1->python-pdfbox) (23.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.8/dist-packages (3.4.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (2.11.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (1.7.3)\n","Requirement already satisfied: numexpr in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (2.8.4)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (3.6.0)\n","Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (1.22.4)\n","Requirement already satisfied: pandas>=1.3.4 in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (1.3.5)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (1.2.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (57.4.0)\n","Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (1.0.2)\n","Requirement already satisfied: funcy in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (1.18)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.3.4->pyLDAvis) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.3.4->pyLDAvis) (2.8.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.1.0)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from gensim->pyLDAvis) (1.15.0)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from gensim->pyLDAvis) (6.3.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->pyLDAvis) (2.0.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: skillNer in /usr/local/lib/python3.8/dist-packages (1.0.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from skillNer) (1.3.5)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from skillNer) (3.7)\n","Requirement already satisfied: jellyfish in /usr/local/lib/python3.8/dist-packages (from skillNer) (0.9.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from skillNer) (1.22.4)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.8/dist-packages (from skillNer) (3.4.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk->skillNer) (4.64.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->skillNer) (7.1.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk->skillNer) (2022.6.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->skillNer) (1.2.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->skillNer) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->skillNer) (2.8.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy->skillNer) (3.3.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy->skillNer) (1.0.9)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy->skillNer) (8.1.7)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy->skillNer) (2.11.3)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy->skillNer) (6.3.0)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy->skillNer) (2.4.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy->skillNer) (2.25.1)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy->skillNer) (0.10.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy->skillNer) (1.10.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy->skillNer) (23.0)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy->skillNer) (1.0.4)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy->skillNer) (0.10.1)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy->skillNer) (0.7.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy->skillNer) (57.4.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy->skillNer) (3.0.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy->skillNer) (2.0.8)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy->skillNer) (3.0.12)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy->skillNer) (2.0.7)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy->skillNer) (4.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->skillNer) (1.15.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy->skillNer) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy->skillNer) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy->skillNer) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy->skillNer) (2022.12.7)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy->skillNer) (0.0.4)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy->skillNer) (0.7.9)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy->skillNer) (2.0.1)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_lg')\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]},{"name":"stdout","output_type":"stream","text":["loading full_matcher ...\n","loading abv_matcher ...\n","loading full_uni_matcher ...\n","loading low_form_matcher ...\n","loading token_matcher ...\n"]}],"source":["!pip install python-pdfbox\n","!pip install pyLDAvis\n","!pip install skillNer\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","\n","import csv\n","import os\n","import glob\n","import re\n","import nltk\n","import spacy\n","from spacy.pipeline import EntityRuler\n","from spacy.lang.en import English\n","from spacy.tokens import Doc\n","import gensim\n","from gensim import corpora\n","import plotly.express as px\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from wordcloud import WordCloud\n","\n","from pdfbox import PDFBox\n","import hashlib # file ids\n","import spacy.cli\n","spacy.cli.download(\"en_core_web_lg\")\n","#warning\n","import warnings \n","warnings.filterwarnings('ignore')\n","\n","nltk.download(['stopwords','wordnet'])\n","\n","nltk.download('omw-1.4')\n","nlp=spacy.load('en_core_web_lg')\n","\n","\n","def extract_pdf_text(folder_path):\n","    text_list = []\n","\n","    for file in glob.glob(os.path.join(folder_path, \"*.pdf\")):\n","        file_name = os.path.basename(file)\n","        pdf = PDFBox()\n","        text = pdf.extract_text(file)\n","        if text:\n","            text_list.append({\"file_name\": file_name, \"text\": text})\n","        else:\n","            with open(f\"{file_name}.txt\", \"w\") as f:\n","                f.write(\"\")\n","\n","    \n","\n","def text_to_csv(folder_path):\n","    csv_file = open('text_files.csv', 'w', newline='')\n","    writer = csv.writer(csv_file)\n","    writer.writerow(['ID', 'filename', 'text'])\n","\n","    def generate_id(filename):\n","        return int(hashlib.md5(filename.encode('utf-8')).hexdigest(), 16)% 100000 #to limit the unique ID to less or equal to 5 digits\n","    \n","    for filename in os.listdir(folder_path):\n","        if filename.endswith(\".txt\"):\n","            file_path = os.path.join(folder_path, filename)\n","            with open(file_path, 'r') as file:\n","                text = file.read()\n","                id = generate_id(filename)\n","                writer.writerow([id, filename, text])\n","\n","    csv_file.close()\n","\n","def load_csv(file_path):\n","    df = pd.read_csv(file_path)\n","    return df\n","\n","from spacy.matcher import PhraseMatcher\n","\n","# load default skills data base\n","from skillNer.general_params import SKILL_DB\n","# import skill extractor\n","from skillNer.skill_extractor_class import SkillExtractor\n","skill_extractor = SkillExtractor(nlp, SKILL_DB, PhraseMatcher)\n","\n","def extract_skills(text):\n","    \n","    annotations = skill_extractor.annotate(text)\n","    doc_node_values = set([x['doc_node_value'] for x in annotations['results']['full_matches']])\n","    return ', '.join(doc_node_values)\n","\n","def create_wordcloud(df, column_name):\n","    skill_cloud = \"\"\n","    for i in df[column_name].values:\n","        skill_cloud += i + \" \"\n","\n","    plt.figure(figsize=(8, 8))\n","\n","    x, y = np.ogrid[:300, :300]\n","\n","    mask = (x - 150) ** 2 + (y - 150) ** 2 > 130 ** 2\n","    mask = 255 * mask.astype(int)\n","\n","    wc = WordCloud(\n","        width=800,\n","        height=800,\n","        background_color=\"white\",\n","        min_font_size=6,\n","        repeat=True,\n","        mask=mask,\n","    )\n","    wc.generate(skill_cloud)\n","\n","    plt.axis(\"off\")\n","    plt.imshow(wc, interpolation=\"bilinear\")\n","    plt.title(\"Most Used Skill Words in Resume\", fontsize=20)\n","\n","\n","def plot_skills_histogram(df):\n","    df_skills = df.copy()\n","    df_skills['skills'] = df_skills['skills'].str.split(',')\n","    df_skills = df_skills.set_index(['ID'])['skills'].apply(pd.Series).stack()\n","    df_skills = df_skills.reset_index()\n","    df_skills = df_skills.rename(columns={0: \"skill\"})\n","    df_skills['skill'].value_counts().plot(kind='bar')\n","    plt.xlabel(\"Skills\")\n","    plt.ylabel(\"Number of Candidates\")\n","    plt.title(\"Skills Histogram\")\n","    plt.show()\n","\n","\n","folder_path = \"/content/drive/MyDrive/Uploaded Resumes/Business Analytics\"\n","\n","\n","# To extract text from pdf files\n","extract_pdf_text(folder_path)\n","\n","\n","# To create a csv file from the extracted text\n","text_to_csv(folder_path)\n","\n","# To load the csv file\n","file_path = 'text_files.csv'\n","df = load_csv(file_path)\n","\n","\n","\n","# To preprocess the text in the csv file\n","clean = []\n","for i in range(df.shape[0]):\n","    review = re.sub(\n","        '(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\"',\n","        \" \",\n","        df[\"text\"].iloc[i],\n","    )\n","    review = review.lower()\n","    review = review.split()\n","    lm = WordNetLemmatizer()\n","    review = [\n","        lm.lemmatize(word)\n","        for word in review\n","        if not word in set(stopwords.words(\"english\"))\n","    ]\n","    review = \" \".join(review)\n","    clean.append(review)\n","\n","df[\"Clean_Resume\"] = clean\n","\n","df['skills'] = df['Clean_Resume'].apply(extract_skills)\n","df.head()\n","\n","create_wordcloud(df, \"skills\")\n","def rank_resumes(df, keywords, scores):\n","    scores_dict = dict(zip(keywords, scores))\n","    df[\"rank\"] = 0\n","    for i in range(df.shape[0]):\n","        for keyword in keywords:\n","            if keyword in df[\"skills\"].iloc[i]:\n","                df[\"rank\"].iloc[i] += scores_dict[keyword]\n","    df = df.sort_values(\"rank\", ascending=False)\n","    return df\n","keywords = ['business development','machine learn', 'time management']# key words to be searched in skills\n","scores = [2, 3]# scores for the above skills in respective order\n","df = rank_resumes(df, keywords, scores)\n","df.to_csv('/content/drive/MyDrive/Uploaded Resumes/ranked_resumesBA.csv', index=False)"]}],"metadata":{"colab":{"provenance":[{"file_id":"1POTiKXQLrdYkFxhKu-O6wFqzVODolUzU","timestamp":1677396288584},{"file_id":"10n0cpUoRqDSzisEUBc7D8HHgKVQaz7GR","timestamp":1676522459279}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}